{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAA-Ped-W8-c2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIMosta/All-About-AI-Python-Edition/blob/master/Course%208-%20Neural%20Networks/AAA_Ped_W8_c2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Eb5rcwfTJ5QI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://docs.google.com/uc?export=download&id=1ap18raVTUCSJeGzTLz9kViroFGvTknrV\">\n",
        "# Artificial Neural Network: "
      ]
    },
    {
      "metadata": {
        "id": "oLTuUgEPpS5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras and Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "sUYvEMW8MB3g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "* **Keras**: a high level **API** to** build** & **train** a **deep learning model**.\n",
        "\n",
        "* It is written in **python** and runs on the top of **Tensorflow**.\n",
        "\n",
        "* Implementation: \n",
        "  *  **tf.keras** : tensorflow implementation of keras\n",
        "  *  **keras**: Keras library (apart)"
      ]
    },
    {
      "metadata": {
        "id": "4ONVb536MHlO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras"
      ]
    },
    {
      "metadata": {
        "id": "3UTIceEiMMwQ",
        "colab_type": "code",
        "outputId": "65946eaa-cffa-40bf-f0ad-9fdd98de80a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "# keras library\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wM-w0Se-zfLU",
        "colab_type": "code",
        "outputId": "c25d308c-48d1-49e8-dbf9-af64a8e5b747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# tensorflow implementation of keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"Tensorflow version:\",tf.VERSION)\n",
        "print(\"Keras version:\",tf.keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 1.13.1\n",
            "Keras version: 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IN_qM-TrMIdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensorflow\n",
        "\n",
        "\n",
        "* **Tensorflow**:  an **open source library** that enables you **develop** and **train** ML models.\n",
        "\n",
        "* There is **2**  important releases of **Tensorflow**:\n",
        "  * Versions 1.*.*  defined by the **APIs r1.***\n",
        "  * Versions 2.*.* defined by the **APIs r2**"
      ]
    },
    {
      "metadata": {
        "id": "2L0EWg3mSgY4",
        "colab_type": "code",
        "outputId": "e9b60ac5-c2de-4883-e65f-7c378f351141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "cell_type": "code",
      "source": [
        "# you have to restart runtime after installation\n",
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "  Using cached https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.6.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.11.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.1.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (40.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.14.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed tensorflow-2.0.0a0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GAwwB5hxTbta",
        "colab_type": "code",
        "outputId": "50b06426-a6ed-4531-daf9-f7868d8e853a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# tensorflow implementation of keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"Tensorflow version:\",tf.version.VERSION)\n",
        "print(\"Keras version:\",tf.keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.0.0-alpha0\n",
            "Keras version: 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQYv_8dGpkxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MLP with tensoflow: High Level API"
      ]
    },
    {
      "metadata": {
        "id": "pioJ-KAG7Rva",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using tensorflow\n",
        "\n",
        "* There are **2** ways to implement artificial neural networks in tensorflow:\n",
        "  * Using the **high level API**\n",
        "  * Using the **low level API**\n",
        "\n",
        "* For example, building and training an **MLP** Using the high level API is simple and trivial. \n",
        "\n",
        "* The low level **API**, permits **more flexibility** in defining the architecture of your model, but will require more code.\n",
        "\n",
        "* In our first example we will use the high level API. In other world, we will use its **premade estimators**\n",
        "\n",
        "* Just a reminder, we will implement the same MLP we defined in the previous lesson."
      ]
    },
    {
      "metadata": {
        "id": "mICOog5PuKLo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Steps\n",
        "\n",
        "* Elements to consider when using a pre-made estimator of tensorflow:\n",
        "\n",
        "  * Define at least **one input function**: it will be used by the estimator to create a structured data that it will use later for training and/or predicting. For our example, the function will return a **tuple** of:\n",
        "    * **Features**: a dictionary with the features names and their corresponding values.\n",
        "    * The corresponding labels\n",
        "\n",
        "  * Define the **features columns**: used to build the estimator. In our case, they will be an array of the **numeric feature columns** constructed using tensorflow. They indicate the features to use from the data returned from the previous defined **input function**.\n",
        "\n",
        "  * Build the estimator and use it for training, predicting … etc"
      ]
    },
    {
      "metadata": {
        "id": "tRkcJVZ-5ctC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the MLP"
      ]
    },
    {
      "metadata": {
        "id": "2-LTjRkkppX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we could use tf.keras.utils.get_file to retreive the\n",
        "# sample dataset\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#load iris datasets\n",
        "X,y= load_iris(return_X_y=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-Qhn2wA9TnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the input function\n",
        "def myInputFunction(x,y=None):\n",
        "\n",
        "    myFeat = dict({\"sepal_length\":x[:,0],\n",
        "                   \"sepal_width\":x[:,1],\n",
        "                   \"petal_length\":x[:,2],\n",
        "                   \"petal_width\":x[:,3]})\n",
        "    myLab = y\n",
        "    return myFeat, myLab\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b8GTR5KdQ3Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the function that construct the features columns\n",
        "def constructFeat(keys):\n",
        "  myFC= []\n",
        "  for k in keys:\n",
        "    myFC.append(tf.feature_column.numeric_column(key=k))\n",
        "  return myFC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DvRSK447Thu",
        "colab_type": "code",
        "outputId": "55cd723b-d9a4-424a-d68f-aeacd2ac3a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# in our example the features columns are simply columns\n",
        "# of numeric values\n",
        " \n",
        "myKeys = [\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]\n",
        "myFeatureColumns= constructFeat(myKeys)\n",
        "\n",
        "# we will build the same MLP we used in the previous lesson\n",
        "## the estimator will be a DNNClassifier\n",
        "## we have to specify one activation function for all \n",
        "## the hidden layer. The output layer will have, by default\n",
        "## the softmax activation function\n",
        "## optimisation using Stochastic gradient descent\n",
        "myMLP = tf.estimator.DNNClassifier(hidden_units=[2], \n",
        "                                   n_classes=3,feature_columns=myFeatureColumns,\n",
        "                                   activation_fn= tf.nn.tanh,\n",
        "                                   optimizer = \"SGD\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0314 12:12:12.450720 140465446565760 estimator.py:1799] Using temporary folder as model directory: /tmp/tmptlqbh_hz\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5VU-3UxVXOAs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training and evaluating\n"
      ]
    },
    {
      "metadata": {
        "id": "rDO70ZdvXKVo",
        "colab_type": "code",
        "outputId": "a66992f6-1367-45b2-f5c3-90ddbf831b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "# training the MLP\n",
        "myMLP.train(input_fn=lambda:myInputFunction(x_train,y_train), max_steps=50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0314 12:11:33.873460 140465446565760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0314 12:11:33.896981 140465446565760 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0314 12:11:33.911891 140465446565760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fc0a26a9198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "1Qnf9ENQicOi",
        "colab_type": "code",
        "outputId": "f5219423-fa1d-492a-a202-7b8814a014dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# evaluating the MLP\n",
        "\n",
        "evalRes = myMLP.evaluate(input_fn=lambda:myInputFunction(x_test,y_test),steps=1)\n",
        "print(\"\\nTest set accuracy: \", np.round(evalRes[\"accuracy\"],3))\n",
        "print(\"All evaluation values:\\n\",evalRes)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy:  1.0\n",
            "All evaluation values:\n",
            " {'accuracy': 1.0, 'average_loss': 0.052664462, 'loss': 0.052664462, 'global_step': 50000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vlv1ukcGFipO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predicting"
      ]
    },
    {
      "metadata": {
        "id": "kIIOAQCiF1X2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will use a portion of our test data (3 samples)\n",
        "# to predict the classification\n",
        "\n",
        "yPred = myMLP.predict(input_fn= lambda: myInputFunction(x_test[:3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOalEq4rbq92",
        "colab_type": "code",
        "outputId": "2f2029bf-1f16-4fcd-ead4-1b1bf4b6fa78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "# labels for the corresponding classes            \n",
        "\n",
        "myClass = [\"Iris-Setosa\",\"Iris-Versicolour\",\"Iris-Virginica\"]\n",
        "for pred,trueL in zip(yPred,y_test[:3]):\n",
        "  print(\"predicted class:\",myClass[pred[\"class_ids\"][0]],\"\\n the true class is:\",\n",
        "        myClass[trueL],\"\\n\\n\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0313 19:19:35.762227 140200898140032 estimator.py:981] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predicted class: Iris-Virginica \n",
            " the true class is: Iris-Virginica \n",
            "\n",
            "\n",
            "predicted class: Iris-Versicolour \n",
            " the true class is: Iris-Versicolour \n",
            "\n",
            "\n",
            "predicted class: Iris-Setosa \n",
            " the true class is: Iris-Setosa \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PcLhZjd9hVlK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1- MLP with Keras"
      ]
    },
    {
      "metadata": {
        "id": "FynlycB5hik2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sequential model\n",
        "\n",
        "\n",
        "* There is **2** ways to build a **ANN** with keras:\n",
        "  * Using a **sequential** model: to build a sequential stack of layers. Ideal for building simple, fully-connected networks.\n",
        "  * Using a**functional** model: ideal to build complex model topologies.\n",
        "\n",
        "* To build our MLP with the Sequential model, we have to:\n",
        "  * Define our layers:\n",
        "    * Specifying the number of neurons\n",
        "    * Selecting the activation function\n",
        "    * Define how the neuron’s weights (and the bias term) will be initialized\n",
        "    * Define the optimization method: it defines how the learning is performed.\n",
        "    * Define the loss function: the function to be minimized during the learning.\n"
      ]
    },
    {
      "metadata": {
        "id": "DVrZpPdfx1Ds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building our model"
      ]
    },
    {
      "metadata": {
        "id": "XmUB8ik55dLA",
        "colab_type": "code",
        "outputId": "4f33ed96-ca2b-4b9d-fddf-72863d415cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "cell_type": "code",
      "source": [
        "# the following code will not work with the version 2.0 of tensorflow\n",
        "# we have to donwgrad tensorflow to the  version 1.13.1\n",
        "\n",
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "  Using cached https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.6.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.14.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (5.1.3)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.0.0a0\n",
            "    Uninstalling tensorflow-2.0.0a0:\n",
            "      Successfully uninstalled tensorflow-2.0.0a0\n",
            "Successfully installed tensorflow-1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UpInY02FhiJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "myMLP2 = keras.Sequential()\n",
        "# we sepecified the activation functions \n",
        "# and the initialization of the weights\n",
        "myMLP2.add(layers.Dense(2, activation='tanh', kernel_initializer=\"TruncatedNormal\",input_shape=(4,)))\n",
        "myMLP2.add(layers.Dense(3, activation='softmax',kernel_initializer=\"TruncatedNormal\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntPmXFcoV_VQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "aJHcOflUWEHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# before starting the training we have to configure our model\n",
        "# with some additional parameters\n",
        "\n",
        "# the optimizer used is the Stochastic gradient descent\n",
        "\n",
        "myMLP2.compile(loss=\"mean_squared_error\",\n",
        "               optimizer=\"sgd\",\n",
        "               metrics=[\"mae\", \"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhfs1pAPbZ4U",
        "colab_type": "code",
        "outputId": "848d2928-7490-459e-9d34-dad237440281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "#training\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# converting the labels array into a multidimensional array (*,3)\n",
        "# with 0, 1 values as we did in the previous lesson\n",
        "Ylabels = to_categorical(y_train, num_classes=3)\n",
        "myMLP2.fit(x_train,Ylabels,epochs=1200,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cccee3ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "e6NNu9RZdQnG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating and predicting"
      ]
    },
    {
      "metadata": {
        "id": "yj0-tqADdTDQ",
        "colab_type": "code",
        "outputId": "6183cc68-ab1b-4193-864b-5c2d69e45946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluating\n",
        "import numpy as np\n",
        "\n",
        "Ytests = to_categorical(y_test, num_classes=3)\n",
        "eval2= myMLP2.evaluate(x_test, Ytests )\n",
        "print(\"Accuracy = \",np.round(eval2[2],3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 122us/step\n",
            "Accuracy =  0.933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a-0AqjurpGN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predicting\n",
        "# we will predict for the 3 first samples from the test data\n",
        "# and compare our predictions with the true labels\n",
        "yPred = myMLP2.predict(x_test[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6fOsE6ZQsNt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# our prediction function\n",
        "def predict(pred):\n",
        "  myClass =  [\"Iris-Setosa\",\"Iris-Versicolour\",\"Iris-Virginica\"]\n",
        "  return myClass[np.argmax(pred)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuE4_Lr4wdvC",
        "colab_type": "code",
        "outputId": "ecb301b2-5f6c-4326-fff4-90dffe075485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(\"The predicted class is: \", predict(yPred[i,:]), \"\\n The true class is: \",\n",
        "        predict(Ytests[i,:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is:  Iris-Setosa \n",
            " The true class is:  Iris-Setosa\n",
            "The predicted class is:  Iris-Virginica \n",
            " The true class is:  Iris-Virginica\n",
            "The predicted class is:  Iris-Versicolour \n",
            " The true class is:  Iris-Versicolour\n",
            "The predicted class is:  Iris-Virginica \n",
            " The true class is:  Iris-Versicolour\n",
            "The predicted class is:  Iris-Setosa \n",
            " The true class is:  Iris-Setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KGQhoLFa6ytS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross Entropy\n",
        "\n",
        "* For a multi-class classification, using the **softmax** activation function, the cross entropy loss function is a better choice to compute the cost to minimize.\n",
        "\n",
        "* It takes into consideration the values of the **probabilities** returned by the output neurons instead of just taking into account correct or the wrong classification:\n",
        ">  $J( w ) = {\\frac{ -1 } { m }} \\sum_{ i=1 }^{m  } \\sum_{ k=1 }^{K } y_k ^{(i) } log ( \\hat {p_k} ^{(i)}  )$\n",
        "* With:\n",
        "  * $K$: number of classes\n",
        "  * $m$: number of samples\n",
        "  * $y_k^{(i)}$: true label valu. Equal to 1 if the sample $i$ belong to the class $k$. Otherwise, it is equal to 0.\n",
        "  *$\\hat {p_k} ^{(i)}$: predicted probability for the sample $i$ for the class $k$\n",
        "  \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "zi0K0Ikgubne",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Applying the cross entropy"
      ]
    },
    {
      "metadata": {
        "id": "umhCCRu8uhY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# before starting the training we have to configure our model\n",
        "# with some additional parameters\n",
        "\n",
        "# the optimizer used is the Stochastic gradient descent\n",
        "\n",
        "\n",
        "myMLP2.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=\"sgd\",\n",
        "               metrics=[\"mae\", \"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ScIbtdw60i8",
        "colab_type": "code",
        "outputId": "8121d219-1eb6-4276-8029-ac6220802668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#training\n",
        "\n",
        "myMLP2.fit(x_train,Ylabels,epochs=1200,verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3cc42df28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "HuJh_i95wEqy",
        "colab_type": "code",
        "outputId": "ece8eae3-8cec-4593-dcc3-76e16010470a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Ytests = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "eval3= myMLP2.evaluate(x_test, Ytests )\n",
        "print(\"Accuracy = \",np.round(eval3[2],3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 49us/step\n",
            "Accuracy =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xTcT5MKTwc_k",
        "colab_type": "code",
        "outputId": "74e012e9-6949-4216-edfd-a24885620e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "yPred2 = myMLP2.predict(x_test[:5])\n",
        "for i in range(5):\n",
        "  print(\"The predicted class is: \", predict(yPred2[i,:]), \"\\n The true class is: \",\n",
        "        predict(Ytests[i,:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted class is:  Iris-Setosa \n",
            " The true class is:  Iris-Setosa\n",
            "The predicted class is:  Iris-Versicolour \n",
            " The true class is:  Iris-Versicolour\n",
            "The predicted class is:  Iris-Versicolour \n",
            " The true class is:  Iris-Versicolour\n",
            "The predicted class is:  Iris-Virginica \n",
            " The true class is:  Iris-Virginica\n",
            "The predicted class is:  Iris-Setosa \n",
            " The true class is:  Iris-Setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pc641owayEHi",
        "colab_type": "code",
        "outputId": "533f1763-1900-4162-8b84-eb98f95fd6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "myClass = [\"Iris-Setosa\",\"Iris-Versicolour\",\"Iris-Virginica\"]\n",
        "\n",
        "\n",
        "myMLP2.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "               optimizer=\"sgd\",\n",
        "               metrics=[\"mae\", \"acc\"])\n",
        "myMLP2.fit(x_train,y_train,epochs=1200,verbose=0)\n",
        "eval4= myMLP2.evaluate(x_test, y_test )\n",
        "print(\"Accuracy = \",np.round(eval4[2],3))\n",
        "\n",
        "yPred3 = myMLP2.predict(x_test[:5])\n",
        "print(yPred3[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 850us/step\n",
            "Accuracy =  0.933\n",
            "[0.00579456 0.58255243 0.411653  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Fac_6g5EwbM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5- More about tensorflow\n"
      ]
    },
    {
      "metadata": {
        "id": "0_ST7zAUFAUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Graph, tensor, operation\n",
        "\n",
        "* With **tensorflow** it is possible to define your model as a **graph**.\n",
        "\n",
        "* The concept is simple: \n",
        "  * You define your **graph**:  the steps of the computation( the tensorflow program)\n",
        "  * You run your graph\n",
        "\n",
        "* Your graph may contain:\n",
        "  * **Tensors**: the central unit of data. Arrays of any number of dimension (a scalar is a tensor with dimension **(rank) **0). They also represent the **Edges** of the graph.\n",
        "  * Operations: the nodes of the graph. They describe calculations with tensors . We can use constructor for operations as follow:\n",
        "  * tensorflow.constant(3.5): creates an operation that will produce the value **3.5** and add it to the **default graph **\n",
        "(TensorFlow provides a default graph that is an implicit argument to all API functions in the same context.)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QZf2Nmd9FJfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensorboard\n",
        "\n",
        "* **Tenorboard** is a suite of **visualization tools**  that can be utilised to visualize  TensorFlow **graph**, plot **quantitative metrics** about the **execution of your graph**.\n",
        "\n",
        "* To use Tensorboard with **google colab**, you can use the library **tensorboardcolab**: "
      ]
    },
    {
      "metadata": {
        "id": "b4rmfIHUGT7G",
        "colab_type": "code",
        "outputId": "4fce68c0-7e13-4d63-bb24-374450add02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://6e7a1d62.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u1kDKdPDu4wM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6- Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "7pLDvlIXrb7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A simple graph in tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "ycmYzH8eE9xE",
        "colab_type": "code",
        "outputId": "cc4bbee0-1547-4d96-cb48-c290afa309ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#delete all previous graphs\n",
        "tf.reset_default_graph()\n",
        "\n",
        "\n",
        "x = tf.constant(7.0)\n",
        "y = tf.constant(8.0)\n",
        "result = x + y\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  writer =tf.summary.FileWriter(\"./Graph\",sess.graph)\n",
        "  print(sess.run(result))\n",
        "  writer.close()\n",
        "  sess.close()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pwidhJNKr1j6",
        "colab_type": "code",
        "outputId": "9105c374-bbef-4442-8c85-b6dc5f98a513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "738W71DeFmVi",
        "colab_type": "code",
        "outputId": "f7b07c3a-4422-49bc-a04f-d207097e176b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%ls Graph/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1552591694.1099d6afc364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hvwU-ML-vqe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tensorboard with Keras"
      ]
    },
    {
      "metadata": {
        "id": "uvZVBzG7bgFW",
        "colab_type": "code",
        "outputId": "2520fc5a-c37d-4c2f-b6b2-b0a4ab1f467a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# use the model compiled with the cross entropy loss function\n",
        "myMLP2.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer=\"sgd\",\n",
        "               metrics=[\"mae\", \"acc\"])\n",
        "\n",
        "Ylabels = to_categorical(y_train, num_classes=3)\n",
        "myMLP2.fit(x_train,Ylabels,epochs=1200,verbose=0,callbacks=[TensorBoardColabCallback(tbc)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cccc83080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "H6_SQiGFqRxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "* Keras, https://www.tensorflow.org/guide/keras\n",
        "* TensorBoard: Visualizing Learning, https://www.tensorflow.org/guide/summaries_and_tensorboard\n",
        "* Keras 2.2.4, https://pypi.org/project/Keras/\n",
        "* Premade Estimators  https://www.tensorflow.org/guide/premade_estimators\n",
        "* Feature Columns, https://www.tensorflow.org/guide/feature_columns\n",
        "* tansig , https://edoras.sdsu.edu/doc/matlab/toolbox/nnet/tansig.html\n",
        "* Hyperbolic functions https://www.math10.com/en/algebra/hyperbolic-functions/hyperbolic-functions.html\n",
        "* Tensorflow,  Introduction, https://www.tensorflow.org/guide/low_level_intro\n",
        "* Hands-on machine learning with Scikit-Learn and TensorFlow: concepts, tools, and techniques to build intelligent systems. O’Reilly Media, Inc."
      ]
    }
  ]
}