{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAA-ped-w8-c1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIMosta/All-About-AI-Python-Edition/blob/master/Course%208-%20Neural%20Networks/AAA_ped_w8_c1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b9q-VxEW5tRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://docs.google.com/uc?export=download&id=1ap18raVTUCSJeGzTLz9kViroFGvTknrV\">\n",
        "# Artificial Neural Networks: Introduction to ANN\n",
        "[Colaboratory Notebook](https://colab.research.google.com/drive/1CqYwu9NzeXuUNeR8RmkDplUd71DHWNod)"
      ]
    },
    {
      "metadata": {
        "id": "H1a7Uuzz8dnI",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Artificial Neural Network: Introduction to ANN](#scrollTo=b9q-VxEW5tRs)\n",
        "\n",
        ">[1- Introduction to ANN](#scrollTo=1oBho425Q7ca)\n",
        "\n",
        ">>[Concept](#scrollTo=yLvtrsm0RcWq)\n",
        "\n",
        ">>[NeuroLab](#scrollTo=A8DvRRWlRdGi)\n",
        "\n",
        ">>[Neurolab example details](#scrollTo=OjzIaOe1RdZ2)\n",
        "\n",
        ">[2- Perceptron](#scrollTo=VL49qQMiRCfC)\n",
        "\n",
        ">>[Definition](#scrollTo=QtI6YjSJRzo8)\n",
        "\n",
        ">>[The functions](#scrollTo=Tg2exEipRz7w)\n",
        "\n",
        ">>[Single Layer Perceptron](#scrollTo=lYnbKQUdR0Ou)\n",
        "\n",
        ">[3-Single Layer Perceptron](#scrollTo=Nhm8OJc_RFU8)\n",
        "\n",
        ">>[SLP Learning](#scrollTo=TOgMnI_CR7QE)\n",
        "\n",
        ">>[SLP Learning: Perceptron Rule](#scrollTo=iJCObGCDR7Wk)\n",
        "\n",
        ">>[Gradient Descent](#scrollTo=Zd06of0ZR7JC)\n",
        "\n",
        ">>[SLP Learning: Delta Rule](#scrollTo=QrWP65T-VEVG)\n",
        "\n",
        ">[4- SLP examples](#scrollTo=Ca8Ofrs7RHwC)\n",
        "\n",
        ">>[With sklearn: perceptron rule](#scrollTo=xn8bZSmqSBwY)\n",
        "\n",
        ">>[Example with neurolab: delta rule](#scrollTo=157T7zEfSB_u)\n",
        "\n",
        ">[5-Multi-Layer Perceptron](#scrollTo=5aXVjrUrRNGi)\n",
        "\n",
        ">>[Multi-Layer Perceptron](#scrollTo=_RT-oRvhVeFM)\n",
        "\n",
        ">>[Backpropagation](#scrollTo=yMgLDZAdSGjG)\n",
        "\n",
        ">>[Example](#scrollTo=Z7prBx0pSGbS)\n",
        "\n",
        ">[6- ANN topologies](#scrollTo=CffbTqAERQKg)\n",
        "\n",
        ">>[FeedForward Neural Networks](#scrollTo=23ma5K3xSKrS)\n",
        "\n",
        ">>[Recurrent Networks](#scrollTo=WIGdB_nfSK9o)\n",
        "\n",
        ">>[Fully connected Neural Network](#scrollTo=_6H6Ca-GSK4-)\n",
        "\n",
        ">[References](#scrollTo=tSbN2yDrRSdW)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1oBho425Q7ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1- Introduction to ANN\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yLvtrsm0RcWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concept\n",
        "\n",
        "* The idea of an **Artificial Neural Network** (**ANN**) is to build a model based on the way the human brain **learns new** things.\n",
        "\n",
        "* It can be used in any type of **machine learning**. It learns by extracting the different underlying patterns in a given data.\n",
        "\n",
        "* This extraction is performed by stages, called **layers**. Each layer, which is composed by a set of **neurons**, will identify a certain pattern. The following layer, will identify another **more complex** pattern, from its previous layer.\n",
        "\n",
        "* The first layer, has the training data as input. It is called the** input layer**. In the last one, the output of the neurons are the final output.  It is called the **output** layer. The layers in between, are called **hidden layers**.\n",
        "* From now, the term **neural network** will mean **artificial neural network**."
      ]
    },
    {
      "metadata": {
        "id": "A8DvRRWlRdGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NeuroLab\n",
        "\n",
        "* Neurolab is Neural Network library for Python. It supports several types of neural networks.\n",
        "\n",
        "* For installation, just type: ```!pip install neurolab```\n",
        "\n",
        "* Like other machine learning techniques, a neural network need to be trained. Can be tested. And will be used to predict results.\n",
        "\n",
        "* Here is an example of how to use neurolab to create a neural network, and how to perform the fore-mentioned tasks:"
      ]
    },
    {
      "metadata": {
        "id": "j45OjrHyWBvK",
        "colab_type": "code",
        "outputId": "3d2de099-a33d-4cd7-e29c-74bcef9f4eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "# installation of neurolab\n",
        "!pip install neurolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neurolab\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/fd/47a9a39158b461b6b862d64c0ad7f679b08ed6d316744299f0db89066342/neurolab-0.3.5.tar.gz (645kB)\n",
            "\u001b[K    100% |████████████████████████████████| 655kB 21.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: neurolab\n",
            "  Building wheel for neurolab (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c6/8f/37/32ab1cf4d601dc0bc49d7241012a4292db4b343bebff5b68e6\n",
            "Successfully built neurolab\n",
            "Installing collected packages: neurolab\n",
            "Successfully installed neurolab-0.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qk9_t_tuZn9K",
        "colab_type": "code",
        "outputId": "23eb32b1-cdc0-44e1-b84e-593a0f363e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import neurolab as nl\n",
        "# Create data\n",
        "myInput = np.random.uniform(-0.5, 0.5, (10, 2))\n",
        "# the labels correspond to the sum of two values\n",
        "myLabels = (myInput[:, 0] + myInput[:, 1]).reshape(10, 1)\n",
        "# Create network with 2 inputs, 5 neurons in hidden layer and 1 in output layer\n",
        "myNN = nl.net.newff([[-0.5, 0.5], [-0.5, 0.5]], [5, 1])\n",
        "# Train process\n",
        "myErr = myNN.train(myInput,myLabels, show=15)\n",
        "\n",
        "# Test and prediction process\n",
        "pred= myNN.sim([[0.2, 0.1]])\n",
        "# the result should be 0.3\n",
        "testErr= np.abs(0.3-pred)\n",
        "print (\"Prediction=\",pred)\n",
        "print (\"Test error = \",testErr)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15; Error: 0.010827781453884296;\n",
            "The goal of learning is reached\n",
            "Prediction= [[0.27888876]]\n",
            "Test error =  [[0.02111124]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JdmOezr3oEou",
        "colab_type": "code",
        "outputId": "07b938a4-edfc-4daa-d3e9-a5793c499ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training errors until converngence:\",myErr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training errors until converngence: [0.32999912867545295, 0.2486661444665599, 0.1292945419367547, 0.0657565980545697, 0.05055297062542579, 0.036675825916531894, 0.02110533590934114, 0.01961050932435214, 0.017889590335269934, 0.017030460795990566, 0.01633692456059261, 0.015204223587932907, 0.013680298794147413, 0.012248254413184468, 0.010827781453884296, 0.010075997772901696, 0.009250550249635933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjzIaOe1RdZ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neurolab example details\n",
        "\n",
        "\n",
        "* Data: **10** samples described by **2** features. The labels are the **sum** of the  **2** features. In fact, the NN tries to model the **sum** function for values ranging from **-0.5** to **0.5 **\n",
        "\n",
        "* After creating the data, the steps were:\n",
        "   * Create an instance of a neural network with specified number of layers and neurons (``` nl.net.newff ```)\n",
        "   * Train the neural network (``` myNN.train ```)\n",
        "   * Predict the output for the value [0.2,0.1] (``` myNN.sim ```)\n",
        "   * Compute the test error (the true label is known: 0.2+0.1)"
      ]
    },
    {
      "metadata": {
        "id": "VL49qQMiRCfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2- Perceptron"
      ]
    },
    {
      "metadata": {
        "id": "QtI6YjSJRzo8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definition\n",
        "\n",
        "* The term **Perceptron** refers to an input layer of data features values, with **forward weighted** connections to an output **layer ** of **one single neuron** , or of **multiple neurons**.\n",
        "\n",
        "* One of the simplest form of a neuron is an **LTU**.\n",
        "\n",
        "* **LTU**, for **L**inear **T**hreshold **U**nit, it is a component (**neuron**) that:\n",
        "  * Computes a **weighted sum** of its inputs: a linear function\n",
        "  * Applies a **step** function to the resulting sum, and **outputs** the results"
      ]
    },
    {
      "metadata": {
        "id": "Tg2exEipRz7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The functions\n",
        "* The weighted sum function, is also called the **Propagation** function.\n",
        "* The step function, can be :\n",
        "  * A **non-linear** function, in this case, it will be  called the **threshold activation function** **(** This is the case of an LTU **)**. For example:\n",
        "    * Heaviside step function:\n",
        "    \n",
        "    $heaviside(z)=\\begin{cases}\n",
        "0,  & \\text{if $z < 0$} \\\\[2ex]\n",
        "1  & \\text{if $z >=0$} \n",
        "\\end{cases}\n",
        "$\n",
        "    * Sign function:\n",
        "        $sgn(z)=\\begin{cases}\n",
        "-1,  & \\text{if $z < 0$} \\\\[2ex]\n",
        "0  & \\text{if $z =0$} \\\\[2ex]\n",
        "1  & \\text{if $z >=0$} \n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "  * A **linear** function, simply called **activation function**. For example:\n",
        "    * The **identity function**: which means that the value computed by the propagation function, is the output value of the neuron.\n",
        "  * A **semi-linear** function, that is **monotonous** and **differentiable**. Also called **activation function**."
      ]
    },
    {
      "metadata": {
        "id": "lYnbKQUdR0Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Single Layer Perceptron\n",
        "* A **S**ingle **L**ayer **P**erceptron **(SLP)**, is simply a Perceptron with only one layer (**without** counting the **input layer** ) .\n",
        "* So, it is composed of an **input** layer and an **output** layer. The later one can have one ore more outputs. So, it can be used for binary and for multioutput classification \n",
        "\n",
        "* Considering an ANN in general, a **Perceptron** is considered as a **feedforward** neural network. We are going to talk about it in the next section.\n",
        "\n",
        "* An **SLP** an apply **2** different kind for **rules** to learn: **the perceptron** rule, or the **delta rule**. Each of the rules is associated with a certain type of activation function.  To apply the delta rule, we need the activation function to be differentiable."
      ]
    },
    {
      "metadata": {
        "id": "Nhm8OJc_RFU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3-Single Layer Perceptron"
      ]
    },
    {
      "metadata": {
        "id": "TOgMnI_CR7QE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SLP Learning\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1tL4Oi1SL7xjsPovWffuTpiyTh5pMhf6t\">\n"
      ]
    },
    {
      "metadata": {
        "id": "iJCObGCDR7Wk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SLP Learning: Perceptron Rule\n",
        "* To update the weights, the following formula is used:\n",
        "$w_{i,j}^{(next~step)} = w_{i,j} + \\eta \\cdot (  y_j -  \\hat y_j) \\cdot  x_i$\n",
        "* The concept is that each **wrong** prediction **reinforces** the **weight** corresponding to the **feature** that would contributed to the **correct prediction**. The computation of the weights is repeated until the samples are classified correctly."
      ]
    },
    {
      "metadata": {
        "id": "Zd06of0ZR7JC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "\n",
        "* The concept of the** gradient** descent:\n",
        "  * With **initial parameters** of a model, predict an **output value**\n",
        "  * Compute the gradient of the “**error**” (“loss”) function (function of the **parameters** of the learning model) at a certain point= the slope of the surface of that function at that point calculated by its **derivative** at that point.\n",
        "  * Update the parameters in order to find the **local minima** by a step **proportional** to **the negative** of that **gradient**. (opposite direction ==> toward the local minima of the function). In the case of :\n",
        "    * **A stochastic gradient descent**: with **one sample**, **predict** →  **update** the parameters for the **next sample** → predict with the next sample with the new parameters \n",
        "    * A **Batch gradient descent**: predict for all samples **==1 epoch → update** the parameters** → **predict again with the new parameters\n",
        "  * Repeat the process in order to **minimize** the error."
      ]
    },
    {
      "metadata": {
        "id": "QrWP65T-VEVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SLP Learning: Delta Rule\n",
        "\n",
        "\n",
        "* With the activation rule being **linear** or **semi-linear** but **differentiable**, the gradient descent is used to update the weights.\n",
        "* The weights are updated as follow:  $w_{i,j}^{next} = w_{i,j} + \\Delta w_{i,j}$\n",
        "  * In general:\n",
        " $\\Delta w = \\frac {- \\eta \\cdot \\partial E} {\\partial w}$\n",
        "  * In a case of **a linear activation function, and a Sum-Squared error function**\n",
        "    * In Online training:\n",
        "for a given sample:\n",
        "$\\Delta w_{ i,j } = \\eta\\cdot x_i \\cdot  ( y_j - \\hat y_j ) = \\eta \\cdot \\delta_j$\n",
        "    *  In Offline training:\n",
        "    $\\Delta w_{ i,j } = \\eta \\cdot   \\displaystyle \\sum_{s \\in X} x_i ^ s \\cdot  ( y_j ^s - \\hat y_j^s) = \\eta \\cdot   \\displaystyle \\sum_{s \\in X} x_i ^ s \\cdot \\delta_j ^{~s}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ca8Ofrs7RHwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4- SLP examples"
      ]
    },
    {
      "metadata": {
        "id": "xn8bZSmqSBwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## With sklearn: perceptron rule"
      ]
    },
    {
      "metadata": {
        "id": "2FiHnx64tsDM",
        "colab_type": "code",
        "outputId": "09f69e97-a76e-476e-a65c-c24745838ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#SLP using Perceptron class\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "#load iris datasets\n",
        "X, y = load_iris(return_X_y=True)\n",
        "# instance of a perceptron: SLP with perceptron rule\n",
        "# learning rate =0.1, maximum of epoch = 5000, without shuffle after \n",
        "# each iteration\n",
        "mySLP = Perceptron(eta0=0.1, max_iter=5000,tol=1e-3,shuffle=False)\n",
        "mySLP.fit(X, y)\n",
        "print (\"The score of the classification (without shuffle) = \", mySLP.score(X, y) )\n",
        "\n",
        "# instance of an other perceptron: SLP with perceptron rule\n",
        "# learning rate =0.1, maximum of epoch = 20, with shuffle after\n",
        "# each iteration\n",
        "mySLPShuf = Perceptron(eta0=0.1, max_iter=20,tol=1e-3,shuffle=True)\n",
        "mySLPShuf.fit(X, y)\n",
        "print (\"The score of the classification (with shuffle) = \", mySLPShuf.score(X, y) )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The score of the classification (without shuffle) =  0.6666666666666666\n",
            "The score of the classification (with shuffle) =  0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rkBsxceXSnbA",
        "colab_type": "code",
        "outputId": "d9cdfc6e-e1e5-498a-e95d-5a01ea5bdb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2188
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "#SLP using SGDClassifier class\n",
        "mySGDCl = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.1,penalty = \"none\", \n",
        "                        max_iter=20, shuffle= True,tol=1e-3, verbose=2,random_state=0\n",
        "                       )\n",
        "mySGDCl.fit(X, y)\n",
        "\n",
        "print (\"The score of the classification (with shuffle) = \", mySGDCl.score(X, y) )\n",
        "\n",
        "print(\"The number of classes = \", len(mySGDCl.classes_))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 150, Avg. loss: 0.065987\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 300, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 450, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 600, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 750, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 900, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.83, NNZs: 4, Bias: 0.100000, T: 1050, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "Convergence after 7 epochs took 0.01 seconds\n",
            "-- Epoch 1\n",
            "Norm: 1.27, NNZs: 4, Bias: 0.000000, T: 150, Avg. loss: 1.399133\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.75, NNZs: 4, Bias: 0.100000, T: 300, Avg. loss: 1.516893\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 2.19, NNZs: 4, Bias: 0.300000, T: 450, Avg. loss: 1.176173\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 2.91, NNZs: 4, Bias: 0.400000, T: 600, Avg. loss: 1.031007\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 3.33, NNZs: 4, Bias: 0.500000, T: 750, Avg. loss: 1.380293\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 3.64, NNZs: 4, Bias: 0.700000, T: 900, Avg. loss: 1.385113\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 3.78, NNZs: 4, Bias: 0.800000, T: 1050, Avg. loss: 0.930087\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 4.04, NNZs: 4, Bias: 1.000000, T: 1200, Avg. loss: 1.136240\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 4.20, NNZs: 4, Bias: 1.200000, T: 1350, Avg. loss: 1.373373\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 4.46, NNZs: 4, Bias: 1.300000, T: 1500, Avg. loss: 1.272333\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 4.60, NNZs: 4, Bias: 1.400000, T: 1650, Avg. loss: 0.814213\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 4.71, NNZs: 4, Bias: 1.600000, T: 1800, Avg. loss: 1.104687\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 4.88, NNZs: 4, Bias: 1.800000, T: 1950, Avg. loss: 1.141947\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 5.04, NNZs: 4, Bias: 1.900000, T: 2100, Avg. loss: 1.257793\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 5.45, NNZs: 4, Bias: 2.100000, T: 2250, Avg. loss: 1.234720\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 5.57, NNZs: 4, Bias: 2.300000, T: 2400, Avg. loss: 1.119900\n",
            "Total training time: 0.01 seconds.\n",
            "Convergence after 16 epochs took 0.01 seconds\n",
            "-- Epoch 1\n",
            "Norm: 2.02, NNZs: 4, Bias: -0.400000, T: 150, Avg. loss: 1.023480\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 3.42, NNZs: 4, Bias: -0.600000, T: 300, Avg. loss: 0.688727\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 3.79, NNZs: 4, Bias: -0.800000, T: 450, Avg. loss: 0.260560\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 4.43, NNZs: 4, Bias: -1.000000, T: 600, Avg. loss: 0.309707\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 5.09, NNZs: 4, Bias: -1.100000, T: 750, Avg. loss: 0.338753\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 5.48, NNZs: 4, Bias: -1.300000, T: 900, Avg. loss: 0.314093\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 5.59, NNZs: 4, Bias: -1.300000, T: 1050, Avg. loss: 0.152213\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 6.03, NNZs: 4, Bias: -1.500000, T: 1200, Avg. loss: 0.281080\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 6.46, NNZs: 4, Bias: -1.600000, T: 1350, Avg. loss: 0.410687\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 6.67, NNZs: 4, Bias: -1.700000, T: 1500, Avg. loss: 0.195233\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 6.75, NNZs: 4, Bias: -1.700000, T: 1650, Avg. loss: 0.124087\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 7.22, NNZs: 4, Bias: -1.900000, T: 1800, Avg. loss: 0.300580\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 7.56, NNZs: 4, Bias: -1.900000, T: 1950, Avg. loss: 0.236360\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 8.00, NNZs: 4, Bias: -2.100000, T: 2100, Avg. loss: 0.192880\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 8.30, NNZs: 4, Bias: -2.300000, T: 2250, Avg. loss: 0.151153\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 8.72, NNZs: 4, Bias: -2.400000, T: 2400, Avg. loss: 0.206760\n",
            "Total training time: 0.01 seconds.\n",
            "Convergence after 16 epochs took 0.01 seconds\n",
            "The score of the classification (with shuffle) =  0.82\n",
            "The number of classes =  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "157T7zEfSB_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example with neurolab: delta rule"
      ]
    },
    {
      "metadata": {
        "id": "95gkfWzCxk2y",
        "colab_type": "code",
        "outputId": "27463658-a640-45ec-e99f-4a195cd53d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# size of the sample data\n",
        "print(\"The number of samples= \",X.shape[0])\n",
        "print(\"The number of Features = \",X.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples=  150\n",
            "The number of Features =  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khI1OBVShPEU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1_mi= X[:,0].min()\n",
        "f1_ma= X[:,0].max()\n",
        "f2_mi= X[:,1].min()\n",
        "f2_ma= X[:,1].max()\n",
        "f3_mi=X[:,2].min()\n",
        "f3_ma= X[:,2].max()\n",
        "f4_mi=X[:,3].min()\n",
        "f4_ma= X[:,3].max()\n",
        "# instantiate an SLP with: 4 input nuerons for th 4 features\n",
        "# with 3 output neurons : to represent the 3 classes\n",
        "#  The learning rule is the Delta rule, the activation function is the \n",
        "# SoftMax function\n",
        "mySLPDelta = nl.net.newp([[f1_mi,f1_ma],[f2_mi,f2_ma],[f3_mi,f3_ma],[f4_mi,f4_ma]],3,\n",
        "                         transf=nl.trans.SoftMax())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUZwaQkhm-fa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# separate the data into test and train samples\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JO0iUqgOspU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we have to construct the target values (true labels)\n",
        "# we will convert each of the labels vectors into a 3 columns\n",
        "# vector\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "myLB = LabelBinarizer()\n",
        "y3_train= myLB.fit_transform(y_train)\n",
        "y3_test= myLB.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Qsn4zHS2IL2",
        "colab_type": "code",
        "outputId": "8529db9d-5c53-4842-d642-d9a8927509d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "1lxOVKuL2OVo",
        "colab_type": "code",
        "outputId": "78448f77-b868-44b7-c9d7-eddd57bae6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "y3_train[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "l_dqS1TnrJ0C",
        "colab_type": "code",
        "outputId": "5ec70447-a30e-495b-8771-7de9a3d43674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "# train the SLP\n",
        "myErr2 = mySLPDelta.train(x_train,y3_train, epochs=1000, show=100, lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100; Error: 3.8853985221501404;\n",
            "Epoch: 200; Error: 3.1950292675296437;\n",
            "Epoch: 300; Error: 2.982660485152986;\n",
            "Epoch: 400; Error: 2.8946913259236964;\n",
            "Epoch: 500; Error: 2.824441033524367;\n",
            "Epoch: 600; Error: 2.7453913597776767;\n",
            "Epoch: 700; Error: 2.6523132225136887;\n",
            "Epoch: 800; Error: 2.547410831400115;\n",
            "Epoch: 900; Error: 2.43713444328122;\n",
            "Epoch: 1000; Error: 2.3293524688849825;\n",
            "The maximum number of train epochs is reached\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CE-EevcLgVgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a prediction function\n",
        "def Predict(x, Net):\n",
        "  if np.ndim(x)==1:    \n",
        "    x=[x]\n",
        "  res = Net.sim(x)\n",
        "  return np.argmax(res,axis=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzZYJxOahZeA",
        "colab_type": "code",
        "outputId": "5bdfedc8-18cc-4d68-ee5a-b4f6005b46dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# compute the accuracy of the SLP predictions\n",
        "# for the training and testing data\n",
        "\n",
        "yPred = Predict(x_train,mySLPDelta)\n",
        "accuracy =np.count_nonzero(yPred== y_train) / y_train.shape[0]\n",
        "print (\"Accuracy of the training = \",np.round(accuracy,2))\n",
        "  \n",
        "yP_test = Predict(x_test,mySLPDelta)\n",
        "accuracy2 =np.count_nonzero(yP_test== y_test) / y_test.shape[0]\n",
        "print (\"Accuracy of the testing = \",np.round(accuracy2,2))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the training =  0.98\n",
            "Accuracy of the testing =  0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5aXVjrUrRNGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5-Multi-Layer Perceptron\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_RT-oRvhVeFM"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-Layer Perceptron\n",
        "* An **MLP** (**M**ulti-**L**ayer **P**erceptron) is an **Perceptron** with **one** or **more** hidden layers.\n",
        "* It is another **Feed Forwad Artificial neural network**. Each of the layers (**except** the **output** layer) includes a **bias** neuron.\n",
        "* An **ANN** with more than **one hidden** layer is a **Deep Neural Network** ( **DNN** ).\n"
      ]
    },
    {
      "metadata": {
        "id": "yMgLDZAdSGjG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Backpropagation\n",
        "\n",
        "* It is a generalization of the **delta rule**. After a **forward pass**, a **backward** pass is applied to **update** the **weights** to back propagate the **errors**, using **gradient descent** procedure.\n",
        "* This forward/backward passes are repeated until the error function is minimized\n",
        "* The formula (of the generalized delta rule) is:\n",
        "  * $\\Delta_{w_{k,h}}= \\eta\\cdot o_k \\cdot \\delta_h$\n",
        "  * $    \\delta_h =\\begin{cases}\n",
        "\\acute f_{act} (net_h) \\cdot (y_h - \\hat y_h  )\\text{ ( h is an output neuron )}  \\\\[2ex]\n",
        "\\displaystyle \\acute f_{act} ( net_h ) \\cdot \\sum_{ l \\in L } \\delta_{ w_{h,l} } (\\text{ h is a neuron of a hidden layer })\n",
        "\\end{cases}\n",
        "$"
      ]
    },
    {
      "metadata": {
        "id": "Z7prBx0pSGbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5jfrUOkx1I18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# an MLP with an input layer with 4 neurons, a hidden layer with\n",
        "# 2 neurons and an output layer with 3 neurons\n",
        "myMLP = nl.net.newff([[f1_mi,f1_ma],[f2_mi,f2_ma],[f3_mi,f3_ma],[f4_mi,f4_ma]],[2, 3],\n",
        "                         [nl.trans.TanSig(), nl.trans.SoftMax()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKIB9vd1zY6k",
        "colab_type": "code",
        "outputId": "9aa6fd45-9246-4018-cbc2-1e1e6d0f35dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# train the MLP\n",
        "myErr2 = myMLP.train(x_train,y3_train, epochs=10000, show=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The goal of learning is reached\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsC4nBQS1Lke",
        "colab_type": "code",
        "outputId": "bff2ef2f-be22-4705-aa26-f45fdc2eb88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# compute the accuracy of the MLP predictions\n",
        "# for the training and testing data\n",
        "\n",
        "yPred = Predict(x_train,myMLP)\n",
        "accuracy =np.count_nonzero(yPred == y_train) / y_train.shape[0]\n",
        "print (\"Accuracy of the training = \",np.round(accuracy,2))\n",
        "  \n",
        "yP_test = Predict(x_test,myMLP)\n",
        "accuracy2 =np.count_nonzero(yP_test== y_test) / y_test.shape[0]\n",
        "print (\"Accuracy of the testing = \",np.round(accuracy2,2))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the training =  1.0\n",
            "Accuracy of the testing =  0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CffbTqAERQKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6- ANN topologies\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "23ma5K3xSKrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FeedForward Neural Networks\n",
        "\n",
        "* We have already seen **feedforward neural networks** (SLP and MLP):\n",
        "  * One input layer + n hidden layers + one output layer (n>=1)\n",
        "  * Connection are only allowed to neurons of the following layers\n",
        "  * They can have shortcut connections: the connection are not set to the following layers but to subsequent layers"
      ]
    },
    {
      "metadata": {
        "id": "UtuV9VuAlvua",
        "colab_type": "code",
        "outputId": "3a245819-1a73-414e-b379-8a41d93def4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install neupy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neupy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a2/4d8dc5d686adcdd3ed2c98c85ccf69370ef0675574b0f8dbb9b91abc978c/neupy-0.8.0-py2.py3-none-any.whl (224kB)\n",
            "\u001b[K    100% |████████████████████████████████| 225kB 7.5MB/s \n",
            "\u001b[?25hCollecting graphviz==0.5.1 (from neupy)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/8d/18e45d3f57adfde20ac831a5ba7144b9e643185e05eb0a02b6f22d076752/graphviz-0.5.1-py2.py3-none-any.whl\n",
            "Collecting tensorflow<=1.12.0,>=1.10.1 (from neupy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 83.1MB 318kB/s \n",
            "\u001b[?25hCollecting progressbar2==3.34.3 (from neupy)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/31/b984e17bcc7491c1baeda3906fe3abc14cb5cd5dbd046ab46d9fc7a2edfd/progressbar2-3.34.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from neupy) (3.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from neupy) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from neupy) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from neupy) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.12.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.11.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (0.7.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<=1.12.0,>=1.10.1->neupy) (3.6.1)\n",
            "Requirement already satisfied: python-utils>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2==3.34.3->neupy) (2.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->neupy) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->neupy) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->neupy) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->neupy) (2.5.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow<=1.12.0,>=1.10.1->neupy) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow<=1.12.0,>=1.10.1->neupy) (3.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<=1.12.0,>=1.10.1->neupy) (40.8.0)\n",
            "Installing collected packages: graphviz, tensorflow, progressbar2, neupy\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Found existing installation: tensorflow 1.13.0rc1\n",
            "    Uninstalling tensorflow-1.13.0rc1:\n",
            "      Successfully uninstalled tensorflow-1.13.0rc1\n",
            "  Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "Successfully installed graphviz-0.5.1 neupy-0.8.0 progressbar2-3.34.3 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-i_JoAEellhw",
        "colab_type": "code",
        "outputId": "f5c7ce65-bd68-4201-9313-c9c20df503ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from neupy import plots\n",
        "\n",
        "# for visualization issues instead for setting the missing connection to 0\n",
        "# we set them to 0.01\n",
        "myFF = 2*(2*[0.01]+2*[3]+3*[0.01]) + 2* (4*[0.01]+ 3*[3]) + 3*(7*[0.01])\n",
        "myFF = np.array(myFF).reshape(7,7)\n",
        "#print(myFF)\n",
        "#hinton diagram corresponding to the feed forward neural network example\n",
        "plots.hinton(myFF,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65169f5630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5IBoIgdEEzkgmsgB0f4Fs5NkFZpr8c0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BLzCY4on4xFq",
        "colab_type": "code",
        "outputId": "e3b84218-4edb-41ce-f273-78b1fa8ca6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "# an other possible visualization\n",
        "# missing connections are represented\n",
        "# by black squares\n",
        "\n",
        "myFF2 = 2*(2*[-1]+2*[3]+3*[-1]) + 2* (4*[-1]+ 3*[3]) + 3*(7*[-1])\n",
        "myFF2 = np.array(myFF2).reshape(7,7)\n",
        "#print(myFF2)\n",
        "#hinton diagram corresponding to the feed forward neural network example\n",
        "plots.hinton(myFF2,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6516c61a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WIGdB_nfSK9o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recurrent Networks\n",
        "* Direct Recurrence:\n",
        "  * Multiple layers with connections allowed to neurons of the following layers\n",
        "  * A  neuron can also be connected to itself\n",
        "  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wlDH_OspBFrO",
        "colab_type": "code",
        "outputId": "7295dfd8-3a5f-42a4-a87a-c61206a3c077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "# direct recurrent connections are represented by \n",
        "# smaller squares than the others connections\n",
        "myDR = ([1]+[0.01]+2*[3]+3*[0.01])+([0.01]+[1]+2*[3]+3*[0.01]) +  \\\n",
        "        (2*[0.01]+[1]+[0.01]+ 3*[3])+(3*[0.01]+[1]+ 3*[3]) +  \\\n",
        "        (4*[0.01] +[1]+ 2*[0.01])+ \\\n",
        "        (5*[0.01]+[1]+[0.01])+ \\\n",
        "        (6*[0.01]+[1])\n",
        "\n",
        "myDR = np.array(myDR).reshape(7,7)\n",
        "#print(myDR)\n",
        "plots.hinton(myDR,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65164f2d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ynO5rKL6GhpI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Indirect Recurrence\n",
        "  * Multiple layers with connections allowed to neurons of the following layers\n",
        "  * Connections are also allowed between neurons and preceding layer\n"
      ]
    },
    {
      "metadata": {
        "id": "nUhHsDrkVTb2",
        "colab_type": "code",
        "outputId": "91ab151b-fafe-4d2c-8bfb-2863b00e2866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "# indirect recurrent connections are represented by \n",
        "# smaller squares than the others connections\n",
        "myIR = 2*(2*[0.01]+2*[3]+3*[0.01])+  \\\n",
        "        2*(2*[1]+2*[0.01]+ 3*[3]) +  \\\n",
        "        3*(2*[0.01] + 2*[1]+3*[0.01])       \n",
        "        \n",
        "\n",
        "myIR = np.array(myIR).reshape(7,7)\n",
        "#print(myIR)\n",
        "plots.hinton(myIR,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f651654ac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qJf048USJpvm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Lateral  Recurrence\n",
        "  * Multiple layers with connections allowed to neurons of the following layers \n",
        "  * Connections between neurons of the same layer are allowed"
      ]
    },
    {
      "metadata": {
        "id": "I8kD9ULdniZw",
        "colab_type": "code",
        "outputId": "e2879606-63ef-4afc-9f4d-c444dad2bcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "# Lateral recurrent connections are represented by \n",
        "# smaller squares than the others connections\n",
        "myLR = ([0.01]+[1]+2*[3]+3*[0.01])+([1]+[0.01]+2*[3]+3*[0.01])+\\\n",
        "        (3*[0.01]+[1]+ 3*[3])+(2*[0.01]+[1]+[0.01]+ 3*[3])+\\\n",
        "        (5*[0.01] + 2*[1])+ \\\n",
        "        (4*[0.01]+[1]+[0.01]+[1])+ \\\n",
        "        (4*[0.01]+2*[1]+[0.01])\n",
        "\n",
        "myLR = np.array(myLR).reshape(7,7)\n",
        "#print(myLR)\n",
        "plots.hinton(myLR,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6516223080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_6H6Ca-GSK4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fully connected Neural Network\n",
        "* Multiple layers with connections allowed from any neuron to any other neuron\n",
        "* Direct recurrence is not allowed\n",
        "* Connections must be symmetric"
      ]
    },
    {
      "metadata": {
        "id": "LFRL8cWVtCZU",
        "colab_type": "code",
        "outputId": "6847be45-ed9f-4340-aedb-557188e192a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "myFC = 49 *[3]\n",
        "myFC = np.array(myFC).reshape(7,7)\n",
        "for i in range(7):\n",
        "  myFC[i,i] = 0.01\n",
        "#print(myFC)\n",
        "plots.hinton(myFC,add_legend=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6516064320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkQOi/R9WayTWSYx4HAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tSbN2yDrRSdW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* Joshi Prateek. Artificial intelligence with Python. Packt Publishing, 2017.\n",
        "\n",
        "* Jake VanderPlas. Python data science handbook: essential tools for working with data. O’Reilly Media, Inc, 2017.\n",
        "\n",
        "\n",
        "* Neural Networks – II, Version 2 CSE IIT, Kharagpur, available at:https://nptel.ac.in/courses/106105078/pdf/Lesson%2038.pdf\n",
        "Isaac Changhau, Loss Functions in Neural Networks, 2017, available at:\n",
        "https://isaacchanghau.github.io/post/loss_functions/\n",
        "\n",
        "* Sebastian Seung, The delta rule, MIT Department of Brain and Cognitive Sciences , Introduction to Neural Networks, 2005, https://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-641j-introduction-to-neural-networks-spring-2005/lecture-notes/lec19_delta.pdf\n",
        "* NeuPy, Neural Networks in Python, http://neupy.com/pages/home.html\n"
      ]
    }
  ]
}