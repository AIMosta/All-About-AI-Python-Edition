{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAA-ped-w5-c2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIMosta/All-About-AI-Python-Edition/blob/master/Course%206-%20Unsupervised%20learning/AAA_ped_w5_c2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b9q-VxEW5tRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://docs.google.com/uc?export=download&id=1ap18raVTUCSJeGzTLz9kViroFGvTknrV\">\n",
        "# Ensemble Leaning: About Ensemble Learning"
      ]
    },
    {
      "metadata": {
        "id": "H1a7Uuzz8dnI",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[Supervised Learning: Introduction to Supervised Learning](#scrollTo=b9q-VxEW5tRs)\n",
        "\n",
        ">[1- Ensemble Learning](#scrollTo=1oBho425Q7ca)\n",
        "\n",
        ">>[Concept](#scrollTo=yLvtrsm0RcWq)\n",
        "\n",
        ">>[Voting](#scrollTo=A8DvRRWlRdGi)\n",
        "\n",
        ">>[Ensemble methods](#scrollTo=OjzIaOe1RdZ2)\n",
        "\n",
        ">[2- Bagging and Pasting](#scrollTo=VL49qQMiRCfC)\n",
        "\n",
        ">>[Deffinition](#scrollTo=QtI6YjSJRzo8)\n",
        "\n",
        ">>[Bagging example using scikit-learn](#scrollTo=Tg2exEipRz7w)\n",
        "\n",
        ">>[Pasting example using sckit-learn](#scrollTo=lYnbKQUdR0Ou)\n",
        "\n",
        ">[3- Features sampling](#scrollTo=Nhm8OJc_RFU8)\n",
        "\n",
        ">>[Definition](#scrollTo=TOgMnI_CR7QE)\n",
        "\n",
        ">>[Example with a Random patches method](#scrollTo=iJCObGCDR7Wk)\n",
        "\n",
        ">>[Example with a Random Subspaces method](#scrollTo=Zd06of0ZR7JC)\n",
        "\n",
        ">[4- Boosting : Adaptive Boosting](#scrollTo=Ca8Ofrs7RHwC)\n",
        "\n",
        ">>[Boosting](#scrollTo=xn8bZSmqSBwY)\n",
        "\n",
        ">>[AdaBoost](#scrollTo=157T7zEfSB_u)\n",
        "\n",
        ">>[SAMME](#scrollTo=ArfuFPFFSB4a)\n",
        "\n",
        ">>[Example](#scrollTo=zDNBX55A9MWc)\n",
        "\n",
        ">[5- Boosting: Gradient boosting](#scrollTo=5aXVjrUrRNGi)\n",
        "\n",
        ">>[Concept](#scrollTo=H71qigLHSGU2)\n",
        "\n",
        ">>[Example: the data](#scrollTo=Z7prBx0pSGbS)\n",
        "\n",
        ">>[Example:  using  a GBRT](#scrollTo=rRQa4nSudjXU)\n",
        "\n",
        ">[6- Stacking or Blending](#scrollTo=CffbTqAERQKg)\n",
        "\n",
        ">>[Concept](#scrollTo=23ma5K3xSKrS)\n",
        "\n",
        ">>[Hold-out set: principle](#scrollTo=WIGdB_nfSK9o)\n",
        "\n",
        ">>[Hold-out set: generalization](#scrollTo=_6H6Ca-GSK4-)\n",
        "\n",
        ">[References](#scrollTo=tSbN2yDrRSdW)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1oBho425Q7ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1- Ensemble Learning"
      ]
    },
    {
      "metadata": {
        "id": "yLvtrsm0RcWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concept\n",
        "* In** Ensemble Learning**, we **combine** several models to build a **better** model. The **algorithm** used in Ensemble learning is called: an **Ensemble Method**.\n",
        "* We can combine **classifiers** or **regressors**.\n",
        "* The models can be all the** same type**,  or** different**. "
      ]
    },
    {
      "metadata": {
        "id": "A8DvRRWlRdGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Voting\n",
        "\n",
        "* Its about: how to select the final prediction.\n",
        "\n",
        "* In Classification \n",
        "\n",
        "  * Hard Voting: \n",
        "    * For each sample, a classifier will make a prediction : a class for that sample\n",
        "    * Select the **most** predicted class by all the classifiers, for that sample .\n",
        "\n",
        "  * Soft Voting: \n",
        "    * available when the classifiers can predict class  probabilities.\n",
        "    * Select the class with the **highest averaged** probability\n",
        "* In Regression\n",
        "\n",
        "  * The **average** of the predicted values.\n",
        "\n",
        "* These methods are the general way to make the predictions. But, they can differ in some specific Ensemble Method. "
      ]
    },
    {
      "metadata": {
        "id": "OjzIaOe1RdZ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ensemble methods\n",
        "* The ensemble methods can vary by: \n",
        " * **Varying** or not the types of the models: use the **same or different **models.\n",
        " * Select the **same sample** only **once** or **several times** in **the same model**.\n",
        "  * **Whether or not** the model use **all the features** or only a **subset** of features.\n",
        " * The models learn in **parallel** or **sequentially**.\n",
        " * The type of **mechanism** used to make a** prediction**."
      ]
    },
    {
      "metadata": {
        "id": "HTCGM7RP2FzO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "   ## Example"
      ]
    },
    {
      "metadata": {
        "id": "t3NiAsxkVdC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import iris plant datasets tools\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# import numpy\n",
        "import numpy as np\n",
        "\n",
        "#import train_test_split from model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8kcpuhKVmPg",
        "colab_type": "code",
        "outputId": "6754566f-173e-44c1-8f86-321bd53d5ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "myIris = load_iris()\n",
        "X = myIris.data\n",
        "y = myIris.target\n",
        "x_train,x_test,y_train,y_test= train_test_split(X, y, test_size=0.25)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(112, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1cTgn3l92FXU",
        "colab_type": "code",
        "outputId": "d18871b8-c788-462d-e55c-71b3b62135af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "logReg = LogisticRegression()\n",
        "decTree = DecisionTreeClassifier()\n",
        "SVMClass = SVC()\n",
        "myEnsembleMethd = VotingClassifier(estimators=[('lr',logReg),('dt',decTree),('svc',SVMClass)]\n",
        "                                   ,voting='hard')\n",
        "myEnsembleMethd.fit(x_train, y_train)\n",
        "y_pred= myEnsembleMethd.predict(x_test.reshape(-1,4))\n",
        "myConfMat = confusion_matrix(y_test,y_pred)\n",
        "print( myConfMat)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VL49qQMiRCfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2- Bagging and Pasting"
      ]
    },
    {
      "metadata": {
        "id": "QtI6YjSJRzo8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deffinition\n",
        "\n",
        "* **Bagging** (or **Bootstrap aggregating**) and **pasting** are **both** ensemble methods that combine** same type of models**. They both train the **models** on **different random sub sets**. All the models run in **parallel.** They use the **voting** mechanism for the final prediction.\n",
        "\n",
        "* Both Bagging and Basting apply **random sampling** :\n",
        "  * The training set of each model is a subset of the original data randomly selected.\n",
        "  * The same sample can be found in different models (different subsets).\n",
        "* The difference is:\n",
        "  * Bagging  : random sampling **with replacement** <==> \n",
        "    * One sample can be found **several times** in the **same model** (same subset).\n",
        "  * Pasting: random sampling **without** replacement <==> \n",
        "    * One sample can be found **only once** in the same model (same subset)."
      ]
    },
    {
      "metadata": {
        "id": "Tg2exEipRz7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bagging example using scikit-learn\n",
        "\n",
        "* We will use an SVC (support vecotr machine classifier) for the bagging example."
      ]
    },
    {
      "metadata": {
        "id": "q-toMW9cXMrg",
        "colab_type": "code",
        "outputId": "88d78e55-29d6-4d35-ef87-9a744fbb0a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "theModel2 = SVC()\n",
        "myBagClass2 = BaggingClassifier(\n",
        "theModel2, n_estimators=300,max_samples=90, bootstrap=True, n_jobs=-1)\n",
        "myBagClass2.fit(x_train, y_train)\n",
        "y_pred = myBagClass2.predict(x_test)\n",
        "\n",
        "\n",
        "myConfMat2 = confusion_matrix(y_test,y_pred)\n",
        "print( myConfMat2)\n",
        "myBagClass2.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9736842105263158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "lYnbKQUdR0Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pasting example using sckit-learn\n",
        "\n",
        "* We will use an SVC (support vecotr machine classifier) for the **bagging **example."
      ]
    },
    {
      "metadata": {
        "id": "59-iUgX8gvDI",
        "colab_type": "code",
        "outputId": "b70d5da1-a77d-46bc-e0ea-51c9fb840181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "myBagClass2P = BaggingClassifier(\n",
        "theModel2, n_estimators=300,max_samples=90, bootstrap=False, n_jobs=-1)\n",
        "myBagClass2P.fit(x_train, y_train)\n",
        "y_pred = myBagClass2P.predict(x_test)\n",
        "\n",
        "\n",
        "myConfMat2P = confusion_matrix(y_test,y_pred)\n",
        "print( myConfMat2P)\n",
        "myBagClass2P.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9736842105263158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "AYZktkmmiK0e",
        "colab_type": "code",
        "outputId": "dcd9737c-4db1-46b5-bd7a-154bb31a9a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "theModel = LogisticRegression()\n",
        "myBagClassP = BaggingClassifier(\n",
        "theModel, n_estimators=300,max_samples=90, bootstrap=False, n_jobs=-1)\n",
        "myBagClassP.fit(x_train, y_train)\n",
        "y_pred = myBagClassP.predict(x_test)\n",
        "\n",
        "\n",
        "myConfMatP = confusion_matrix(y_test,y_pred)\n",
        "print( myConfMatP)\n",
        "myBagClassP.score(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0]\n",
            " [ 0 10  2]\n",
            " [ 0  0 10]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "Nhm8OJc_RFU8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3- Features sampling"
      ]
    },
    {
      "metadata": {
        "id": "TOgMnI_CR7QE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Definition\n",
        "\n",
        "* All the following methods use **features sampling**: each model will be trained in a **random subset** of features.\n",
        "\n",
        "* **Sampling features** can be **with **or **without replacement**.\n",
        "\n",
        "\n",
        "* Random patches method\n",
        "\n",
        "  * **Sampling **both **“**training instances**” and “**features**”\n",
        "\n",
        "\n",
        "\n",
        "* Random subspaces method\n",
        "\n",
        "  * Keeping all **bold text** “**training**” instances but “**sampling” features**"
      ]
    },
    {
      "metadata": {
        "id": "iJCObGCDR7Wk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example with a Random patches method"
      ]
    },
    {
      "metadata": {
        "id": "loxMUDn037Q8",
        "colab_type": "code",
        "outputId": "c6f5adc6-d16e-44f2-a01c-a263c3eba214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        " # import the tool for generating the data\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "\n",
        "# generate a random regression problem\n",
        "xr,yr= make_regression( n_features = 20)\n",
        "\n",
        "xr_train,xr_test,yr_train,yr_test= train_test_split(xr, yr, test_size=0.25)\n",
        "print(xr_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7wOqlUya4PZy",
        "colab_type": "code",
        "outputId": "b69fe35c-e9a5-4c28-8139-f1a4b6d3740a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "theModelR = LinearRegression()\n",
        "myBagReg = BaggingRegressor(\n",
        "               theModelR, n_estimators=20,max_samples=50,max_features=15, \n",
        "               bootstrap=True, bootstrap_features= True, n_jobs=-1)\n",
        "\n",
        "myBagReg.fit(xr_train, yr_train)\n",
        "yr_pred = myBagReg.predict(xr_test)\n",
        "myBagReg.score(xr_test,yr_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.670360383167735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Zd06of0ZR7JC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example with a Random Subspaces method\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gzYxL9ZkDL3G",
        "colab_type": "code",
        "outputId": "de753a5d-7d25-493e-800e-f3a1d0ab5494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "myBagReg2 = BaggingRegressor(\n",
        "               theModelR, n_estimators=45,max_samples=1.0,max_features=1, \n",
        "               bootstrap=False, bootstrap_features=False, n_jobs=-1)\n",
        "\n",
        "myBagReg2.fit(xr_train, yr_train)\n",
        "yr_pred2 = myBagReg2.predict(xr_test)\n",
        "myBagReg2.score(xr_test,yr_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.041318141556522796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Ca8Ofrs7RHwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4- Boosting : Adaptive Boosting"
      ]
    },
    {
      "metadata": {
        "id": "xn8bZSmqSBwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Boosting\n",
        "\n",
        "\n",
        "* Boosting **bold text** : Ensemble method, that combines **several weak learners** into a** stronger** learner.\n",
        "\n",
        "* This is done by training the **models sequentially** ==> each model **correct (boost)** its **predecessor**.\n",
        "\n",
        "* The most known boosting methods are: **Adaptive Boosting** and **Gradient Boosting**.\n",
        "\n",
        "  * **AdaBoost**: each new predictor focus on the training samples that its **predecessor underfitted **( for example: misclassified in a classification problem) by modifying the instances weight .\n",
        "  * **Gradient Boosting**: the new predictor tries to** fit**\n",
        "to the **residual errors** made by the **previous predictor**.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "157T7zEfSB_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## AdaBoost\n",
        "\n",
        "* Applicable in binary classification.\n",
        "* The steps of the algorithm are as follow:\n",
        "  *  initialize the samples weight $ w^i$ (for the first predictor ) by $\\frac{1}{m}$. $m$ is the number of the training samples.\n",
        "  * for each predictor $j$, after training, and predicting,  compute:\n",
        "    * the weighted error rate : $r_j = \\frac {\\sum_{i=1_{y_{true}(i) \\ne y_{pred}(i)}}^m  w^i}{\\sum_{i=1} ^m w^i}$\n",
        "    * compute the $j$ predictor's weight:\n",
        "    $\\alpha_j = \\eta \\log \\frac {1 - r_j}{r_j}$. $\\eta$ is the learning rate parameter.\n",
        "    * Compute the new weights (to be used by the following new predictor $j+1$) :\n",
        " $ w^i = w^i , if,  y_{true}(i) = y_{pred}(i) $\n",
        "  $w^i = w^i \\exp(\\alpha_j),  if, y_{true}(i) \\neq y_{pred}(i) $\n",
        "  \n",
        "    * Normalize the new weights $ w^i$ by: $w^i=\\frac{1}{\\sum_{i=1} ^m w^i}$\n",
        "    * The process is repeated until  the **perfect predictor** is found, or the ** maximum** number of **predictors** is reached.\n",
        " * To make a prediction: \n",
        "   * make a prediction with each predictor $j$ from the resulting $N$ predictors.\n",
        "   * attribute a weight to each  prediction by the predictor's  $j$  weight.$\\alpha_j$\n",
        "   * for each sample $x$ select the class $k$ that receives the majority of weighted votes: for each predicted class $k$ sum up the corresponding $\\alpha_j$weights, then select the class $k$ with the biggest sum.\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "ArfuFPFFSB4a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SAMME\n",
        "\n",
        "* SAMME  : **S**tagewise **A**dditive **M**odeling using a **M**ulti-class **E**xponential loss function\n",
        "\n",
        "* Enhanced version of **AdaBoost**, applicable in **multiclass** classification.\n",
        "\n",
        "* Same steps as AdaBoost, just the **$\\alpha $** weight is computed differently:  $\\alpha_j = \\eta *(\\log \\frac {1 - r_j}{r_j} + log(K-1))$. $K$ is the number of classes.\n"
      ]
    },
    {
      "metadata": {
        "id": "zDNBX55A9MWc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "* We will apply SAMME algorithm using Scikit Learn on the previous data.\n",
        "* There is another version of the algorithme **SAMME.R** applicable by default if the model use implements **predict_proba** function."
      ]
    },
    {
      "metadata": {
        "id": "qdLVIOdq9Lvc",
        "colab_type": "code",
        "outputId": "87270435-e704-434f-d706-8d618d36c625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "  # we will use  a decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "theModel4 = DecisionTreeClassifier(max_depth=1)\n",
        "mySAMME = AdaBoostClassifier(theModel4, n_estimators=200,                           \n",
        "                           algorithm=\"SAMME\", learning_rate=1\n",
        "                           )\n",
        "\n",
        "mySAMME.fit(x_train, y_train)\n",
        "y_pred = mySAMME.predict(x_test)\n",
        "\n",
        "myConfMat3 = confusion_matrix(y_test,y_pred)\n",
        "print(myConfMat3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  0  0]\n",
            " [ 0 11  1]\n",
            " [ 0  0 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5aXVjrUrRNGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5- Boosting: Gradient boosting"
      ]
    },
    {
      "metadata": {
        "id": "H71qigLHSGU2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concept\n",
        "\n",
        "\n",
        "1. The predictor will be first trained on a set of data: $x$,$y$\n",
        "2. The residual errors are computed from its prediction: $r = y - y_{pred}$\n",
        "3. A new predictor will be trained with the new set of data: $x$,$r$\n",
        "4. The residual errors are computed again  as follow: $r2 = r - r_{pred}$\n",
        "5. The steps 3 and 4 are repeated until: you predict using all the predefined number of predictors, or you  determine the optimal consecutive predictors (the least generated error) and you select those predictors as your final model. Or, you continue adding predictors until the errors will not diminish \n",
        "6. The final prediction will be the sum of all the predictions.\n",
        "\n",
        "\n",
        "\n",
        "* Scikit learn implements gradient tree boosting: the models used are decision trees."
      ]
    },
    {
      "metadata": {
        "id": "Z7prBx0pSGbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example: the data"
      ]
    },
    {
      "metadata": {
        "id": "IWNZr7MtM5cG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we will use load_boston utilities to load our data\n",
        "# we will considere only the feature with the indices 12 (the last one): 'LSTAT'\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "mydata =load_boston()\n",
        "xr2 = mydata.data[:,[12]]\n",
        "yr2 = mydata.target\n",
        "xr2_train,xr2_test,yr2_train,yr2_test= train_test_split(xr2, yr2, test_size=0.25)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQsBMHoRd5mU",
        "colab_type": "code",
        "outputId": "1b53277b-f6b7-45f0-ca83-2892385a60bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "cell_type": "code",
      "source": [
        "print(mydata.DESCR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rRQa4nSudjXU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example:  using  a GBRT\n",
        "* **GBRT** for **G**radient **B**oosted **R**egression **T**rees"
      ]
    },
    {
      "metadata": {
        "id": "5U_XR04gfC04",
        "colab_type": "code",
        "outputId": "9ccb1540-5193-4e49-8aeb-e8a16b671a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "myGBRT = GradientBoostingRegressor(max_depth=2, n_estimators=45)\n",
        "myGBRT.fit(xr2_train, yr2_train)\n",
        "\n",
        "# xnew to draw the model\n",
        "xnew= np.linspace(4,40,2000).reshape(-1,1)\n",
        "ypred= myGBRT.predict(xnew)\n",
        "plt.plot(xnew, ypred,color=\"red\")\n",
        "plt.scatter(xr2_train,yr2_train,marker=\".\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f49e246ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICLegiAIGYiItyAIQgYi4i0IgpCB/H9HUVRK3bA2fQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f49e1282208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QP3PbUNNd_28",
        "colab_type": "code",
        "outputId": "b0e6367e-8f6f-45a1-cc6c-cf89784fb62b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "# testing the model\n",
        "ypred= myGBRT.predict(xr2_test)\n",
        "\n",
        "#plot the true values: in green and the predicted values: in black\n",
        "plt.scatter(xr2_test,yr2_test,color=\"green\",marker=\".\")\n",
        "plt.scatter(xr2_test,ypred,color=\"black\",marker=\"+\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "print (MSE(yr2_test,ypred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.701804841167945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f49de7e8630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CffbTqAERQKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6- Stacking or Blending"
      ]
    },
    {
      "metadata": {
        "id": "23ma5K3xSKrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concept\n",
        "\n",
        "* The idea here, is to train a model to** learn** how to** aggregate** the ensemble models predictions.\n",
        "\n",
        "* The method is composed of:\n",
        "  * Learner models : that will fit to the data, and make the predictions.\n",
        "  * **Blender**: the final model  or meta learner, that will make the final prediction.\n",
        "\n",
        "* There are different methods to train the blender:\n",
        "  * Hold-out set: Blending\n",
        "  * Out-of-fold: Stacking"
      ]
    },
    {
      "metadata": {
        "id": "WIGdB_nfSK9o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hold-out set: principle\n",
        "\n",
        "* An example using 3 Predictors and 1 blender (2 layers). The 3 predictors will form **a layer** ,  and another predictor will be the **second layer**.\n",
        "\n",
        "  * First, the training data is subdivided into 2 subsets.\n",
        "  * The **first subset** is used by the first layer to train.\n",
        "  * The **trained** layer will use the** second subset**  to predict new values:  3 predictors ==>  3 set of predictions\n",
        "  * The 3 set of predictions will form a new set of values: each set will represent a feature ==> x values with 3 features.\n",
        "  * The target values will be the target values of the orginal subsest of the training data (the second one used for prediction) .\n",
        "  * The new set values will be used by the blender (another model) to train.\n",
        " \n",
        "* To make a prediction with new instances:\n",
        "  *  The new instance will go through the first layer.\n",
        "  * The resulting predictions will  serve as input for the second layer.\n",
        "  * The prediction made by this later one is the final result.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jQPFYQx1I-Ei",
        "colab_type": "code",
        "outputId": "5dfee9e2-1e97-411f-a8f9-67dc4614a0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# predictors composing the first layer\n",
        "myModel1 = SVR(kernel='poly')\n",
        "myModel2 = LinearRegression()\n",
        "myModel3 = DecisionTreeRegressor()\n",
        "\n",
        "# the model choosen for the blender\n",
        "myBlender = SVR(kernel='linear')\n",
        "\n",
        "#subdividing the= training data into 2 subsets\n",
        "size=  int(xr2_train.shape[0]/2)\n",
        "\n",
        "subXR1=xr2_train[:size]\n",
        "subXR2=xr2_train[size:]\n",
        "\n",
        "subYR1= yr2_train[:size]\n",
        "subYR2= yr2_train[size:]\n",
        "print(subXR1.shape,subXR2.shape,subYR1.shape,subYR2.shape)\n",
        "\n",
        "# training the first layer\n",
        "myModel1.fit(subXR1,subYR1)\n",
        "myModel2.fit(subXR1,subYR1)\n",
        "myModel3.fit(subXR1,subYR1)\n",
        "\n",
        "# predicting with the second subset\n",
        "\n",
        "pred1 = myModel1.predict(subXR2)\n",
        "pred2 = myModel2.predict(subXR2)\n",
        "pred3 = myModel3.predict(subXR2)\n",
        "\n",
        "\n",
        "# constructing the new x values\n",
        "xnew = np.append(pred1.reshape(-1,1), pred2.reshape(-1,1), axis= 1)\n",
        "xnew= np.append(xnew, pred3.reshape(-1,1),axis = 1)\n",
        "print(xnew.shape)\n",
        "\n",
        "\n",
        "# train on the previous predicted values\n",
        "\n",
        "myBlender.fit(xnew,subYR2)\n",
        "\n",
        "# predicting on test data\n",
        "\n",
        "# predicting with the first layer\n",
        "\n",
        "pred1 = myModel1.predict(xr2_test)\n",
        "pred2 = myModel2.predict(xr2_test)\n",
        "pred3 = myModel3.predict(xr2_test)\n",
        "\n",
        "# create the x vlaues\n",
        "# constructing the new x values\n",
        "xnew_test = np.append(pred1.reshape(-1,1), pred2.reshape(-1,1), axis= 1)\n",
        "xnew_test= np.append(xnew_test, pred3.reshape(-1,1),axis = 1)\n",
        "print(xnew_test.shape)\n",
        "\n",
        "\n",
        "# predicting with the second layer\n",
        "myFP= myBlender.predict(xnew_test)\n",
        "print(myBlender.score(xnew_test,yr2_test))\n",
        "\n",
        "# printing the mean square error\n",
        "print (MSE(yr2_test,myFP))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(189, 1) (190, 1) (189,) (190,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(190, 3)\n",
            "(127, 3)\n",
            "0.6411442145726178\n",
            "27.90487595475314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_6H6Ca-GSK4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hold-out set: generalization\n",
        "\n",
        "* Its possible to train several type of blenders. And , each one can be a set of models.\n",
        "\n",
        "* The idea is to divide the original training set into several subsets: n subsets ==> n layers (n-1 blending phase)\n",
        "\n",
        "* The first set of predictors will  train from the first subset, and make prediction with the second one.\n",
        "\n",
        "* The second set of predictors will train from the previous predictions. And then make new predictions using the third subset.\n",
        "\n",
        "* The process is repeated until the last subset of predictors: it will train from the last predictions made by the previous predictors using the last subset of data. "
      ]
    },
    {
      "metadata": {
        "id": "tSbN2yDrRSdW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* Aurélien Géron. Hands-on machine learning with Scikit-Learn and Tensor-Flow: concepts, tools, and techniques to build intelligent systems. O’Reilly Media, Inc, 2017.\n",
        "\n",
        "* Scikit-learn.org. scikit-learn, machine learning in python. On-line at https://scikit-learn.org/stable/. Accessed on 03-11-2018."
      ]
    }
  ]
}